---
title: "Assignments"
output:
html_document:
  toc: yes
  toc_float: yes
  collapsed: no
  number_sections: no
    toc_depth: 1
    pdf_document:
    toc: true
    toc_depth: 1
---

Niko Amber Assignments!

# Assignment 1  
 
**Collaborators: Eliza Epstein. **

### Problem 1 


Answer: I've loaded the library!

Load the USArrests dataset and rename it `dat`. Note that this dataset comes with R, in the package datasets, so there's no need to load data from your computer. Why is it useful to rename the dataset?

```{r}
dat <- USArrests

```

Answer: It is beneficial to rename the data set, so we can replicate analyses without disturbing the 
original data set. Additionally, it is nice to rename your data set to know exactly it is called

### Problem 2

First I am making states lowercarse, to be used as variables later.

```{r}
dat$state <- tolower(rownames(USArrests))
```

This dataset has the state names as row names, so we just want to make them into a new variable. We also make them all lower case, because that will help us draw a map later - the map function requires the states to be lower case.


List the variables contained in the dataset `USArrests`.

The variables contained in the dataset 'USArrests' are Murder, Assault, and Rape. Additionally, the data set shows us what percentage of people live in urban areas.
```{r}
USArrests
```

### Problem 3 

What type of variable (from the DVB chapter) is `Murder`? 

Answer: Murder is a categorical variable, it is one of many catagories that crime falls into.
It is not ordinal, there is no ordering of crime.

What R Type of variable is it?

Answer: 'Murder' is a character variable, it contains information that isn't numeric.


### Problem 4

What information is contained in this dataset, in general? What do the numbers mean? 

Answer: The Data set USArrests contains data about the rate of arrests for murder, rape and assault per 100,000 residents in each US state in 1973. The data set also includes the percent of the population living in urban cities in each state. The collums represent each type or crime (and urban population percentage) The numbers in each row are the rate of arrests per state (per 100,000).

### Problem 5

Draw a (histogram) bar graph of `Murder` with proper labels and title.
I used a bar graph instead of a histogram because I feel that is a better way to represent this data.

```{r}

barplot(USArrests$Murder , names.arg = state.name,las=2, xlab = "States", ylab = "Rate of Murder Arrests per 100,000 people",
        main = "Arrests for Murder in the United States 1973")
```

### Problem 6

Please summarize `Murder` quantitatively. What are its mean and median? What is the difference between mean and median? What is a quartile, and why do you think R gives you the 1st Qu. and 3rd Qu.?

I used the summary function to gather this information 

```{r}
summary(USArrests$Murder)
```

The mean for murder is 7.788 meaning this is the average rate of people (per 100,000) murdered in each US state in 1973. The median for murder is 7.250 meaning in the United States in 1973 half of the states had a rate per 100,000 more that 7.250 and half had fewer. Median is the middle of numbers in a data set, while mean is the average of all numbers in said set. If the data is evenly distributed the median will equal the mean.

A quartile is when the data is divided into four equal parts: the 1st, 2nd, 3rd, and 4th quartile. R gives the 1st and 3rd quartile because it represents the middle of the data. 1st quartile is lowest 25% and 3rd quartile is highest 25%.

### Problem 7

Repeat the same steps you followed for `Murder`, for the variables `Assault` and `Rape`. Now plot all three histograms together. You can do this by using the command `par(mfrow=c(3,1))` and then plotting each of the three. 

Note: I used bar graphs

```{r, echo = TRUE, fig.width = 5, fig.height = 8}
barplot(USArrests$Murder , names.arg = state.name,las=2, xlab = "States", ylab = "Rate of Murder Arrests per 100,000 people",
        main = "Arrests for Murder in the United States 1973")
#Bar plot for rape arrests
barplot(USArrests$Rape , names.arg = state.name,las=2, xlab = "States", ylab = "Rate of Arrests for Rapes per 100,000 people",
        main = "Rate of Arrests for Rape in the United States in 1973")

#Bar plot for assault arrests
barplot(USArrests$Assault , names.arg = state.name,las=2, xlab = "States", ylab = "Rate of Arrests for Assault per 100,000",
        main = "Rate of Arrests for Assaults in the United States")


#plotting the graphs together

par(mfrow=c(3,1)) 
barplot(USArrests$Murder , names.arg = state.name,las=2, xlab = "States", ylab = "Rate of Murder Arrests per 100,000 people",
        main = "Arrests for Murder in the United States 1973")
#Bar plot for rape arrests
barplot(USArrests$Rape , names.arg = state.name,las=2, xlab = "States", ylab = "Rate of Arrests for Rapes per 100,000 people",
        main = "Rate of Arrests for Rape in the United States in 1973")

#Bar plot for assault arrests
barplot(USArrests$Assault , names.arg = state.name,las=2, xlab = "States", ylab = "Rate of Arrests for Assault per 100,000",
        main = "Rate of Arrests for Assaults in the United States")
par
```

What does the command par do, in your own words (you can look this up by asking R `?par`)?

Answer: This command allows R to set paramaters, this way multiple data sets can be graphed together.

What can you learn from bar graphs the histograms together?

Answer: When we plot these bar graphs together we can compare each state's arrest rates for different crimes. For example, when looking at the bar graphs it is easy to see that North Carolina's arrest rate for assault is much higher than the arrest rate for rape. This can lead researchers to ask questions: why were there more arrests for assaults? Were there possible sexually based assault that should have been charged as rape?
  
### Problem 8

In the console below (not in text), type `install.packages("maps")` and press Enter, and then type `install.packages("ggplot2")` and press Enter. This will install the packages so you can load the libraries.

Run this code:

```{r, fig.width = 7.5, fig.height = 4}
library('maps') 
library('ggplot2') 

#this code creates a map
ggplot(dat, aes(map_id=state, fill=Murder)) + 
  geom_map(map=map_data("state")) + 
  expand_limits(x=map_data("state")$long, y=map_data("state")$lat)
```

What does this code do? Explain what each line is doing.

Answer: This code creates a colored map that uses our data set to show murder rates. The lighter the blue, the higher the murder rate. 

The first line of code creates a map that is divided by states. TYhe first line also applies the data set to the map, so the color of the state will be lighter if murder rates are higher. The second line of code designs the map by breaking it up by state. The last line of code expands the limits of the map

Here is my histogram

```{r}
hist(dat$Murder, main = "Murder Rate in The United States in 1973", xlab = "Murder Rate", ylab = "Frequency",
color= "purple")
```

$$\\[2in]$$




# Assignment 2 

### Problem 1
```{r}
knitr::opts_chunk$set(echo = TRUE)

setwd("/Users/nikoamber/Library/Mobile Documents/com~apple~CloudDocs/Penn/Freshman Fall/Criminology/Assignment 2")

dat <- read.csv(file = 'dat.nsduh.small.1.csv')

names(dat)

nrow(dat)

ncol(dat)

```
There are seven columns and 171 rows

### Problem 2

__Describe the variables in the dataset.__

The variables in the data are:

MJAGE which is how old the participants are the first time they used marijuana/hashish. It is a quantitative continuous variable.

CIGAGE which is how old the participants were when they first started smoking cigarettes everyday. It is a quantitative continuous variable.

IRALCAGE which is how old the participants were when they first tried alcohol. it is a quantitative continuous variable.

AGE2S which is the age of the respondents of the survey, categorized into groups. It is a categorical nominal variable.

IRSEX which is which sex participants identify as. It is a categorical, nominal variable. Participants can only identify as male or female. which is coded as 1 or 2.

SEXATRACT which is who participants of the study are attracted to. It is a categorical, nominal variable. Participants identified their sexual preference on a catagory scale of 1-6, but there is no ranking.

SPEAKENGL which is how well do participants speak English. It is a categorical, ordinal variable. Participants rate on a scale of 1-4 where 1 is speaking English well and 4 is not at all.
  
__What is this dataset about? Who collected the data, what kind of sample is it, and what was the purpose of generating the data?__

This data set is a sample form a 2019 survey taken by the National Survey of Drug Use and Health. This data is only a sample of the survey and has the first 1000 values, and does not include missing values. The data is a random sampling of the US population, and it can be used to tell us more about the US population and their relationship with drugs.

## Problem 3: Age and gender

__What is the age distribution of the sample like? Make sure you read the codebook to know what the variable values mean.__
```{r}
hist(dat$age2, main= "Histogram of ages of participants of 2019 NSDUH survey", xlab= "Ages in Groups", ylab= "Frequency" )
```

## Problem 3: Age and gender

__What is the age distribution of the sample like? Make sure you read the codebook to know what the variable values mean.__

```{r}
hist(dat$age2, main= "Histogram of ages of participants of 2019 NSDUH survey", xlab= "Ages in Groups", ylab= "Frequency" )

```
The age distribution is from ages 12-65+. As mentioned in the code book, it is grouped in sections. but not every group holds the same number of years. Because of this it is difficult to see the age distribution properly. While it appears that most participants are in group 15, group 15 has ages 35-49 (14 years) while groups 1-9 only have one year.

__Do you think this age distribution representative of the US population? Why or why  not?__

Because of the way the ages are grouped together, this histogram is left skewed. However, there are no respondents below the age of 12, which makes sense given the content of this survey. There are also very few older participants. Therefore this data is probably a good representation of the US population for the purposes of this study, but obviously is not representative of the entire US population.

__Is the sample balanced in terms of gender? If not, are there more females or males?__

```{r}
table(dat$irsex)
```
There are more males than females in this sample. It is not representative of the US population, because in the population there are slightly more women then men. This scale is also on a bianary, when there are many people in the United States who may not identify with one of these two genders. According to the code book, the entire data set has more females then males, but in these 1000 data points, there are more males then females.

__Use this code to draw a stacked bar plot to view the relationship between sex and age. What can you conclude from this plot?__

```{r}
tab.agesex <- table(dat$irsex, dat$age2)
barplot(tab.agesex,
        main = "Stacked barchart",
        xlab = "Age category", ylab = "Frequency",
        legend.text = rownames(tab.agesex),
        beside = FALSE) # Stacked bars (default)
```

In the age category 15, that represents respondents between 35 and 49 and 26-29, there is about an even distribution between men and women. However, the younger groups tend to have more female participants then male (group 8 does not have any male respondents) and the groups above 15 seerm to have a larger percentage of men.


## Problem 4: Substance use

__For which of the three substances included in the dataset (marijuana, alcohol, and cigarettes) do individuals tend to use the substance earlier?__

```{r}
par(mfrow=c (1,1))
plot(dat$age2, dat$mjage)
cor(dat$age2, dat$mjage)
cor(dat$age2, dat$cigage)
plot(dat$age2, dat$cigage)
cor(dat$age2, dat$iralcage)
plot(dat$age2, dat$iralcage)
```
People in the survey tended to use alcohol earlier than other substances. This can be seen by the scatter plots. Additionally, alcohol has the lowest correlation coefficient.

## Problem 5: Sexual attraction

__What does the distribution of sexual attraction look like? Is this what you expected?__

```{r}
counts <- table(dat$sexatract)
barplot(counts, main= "Sexual Attraction Preferences Based on Small Sample from NSDUH 2019", xlab= "Category", ylab="Number of Respondents")
```
According to this bargraph, most people answered 1, which indicates preference for the opposite sex.This does not surprise me, as most people in the United States are heterosexual, however I would expect more people to answer 3 or 5.

__What is the distribution of sexual attraction by gender?__

```{r}
counts <- table(dat$irsex, dat$sexatract)
barplot(counts, main= "Sexual Attraction Preferences Seperated by Gender ", xlab="Categories", ylab= "Number of Respondents")
```

Group 1, which is heterosexual, is mainly composed of males. While group 3, which is bisexual is completely female. Group 6, which is homosexual, is also completely male.

## Problem 6: English speaking

__What does the distribution of English speaking look like in the sample? Is this what you might expect for a random sample of the US population?__

```{r}
counts <- table(dat$speakengl)
barplot(counts, main= "How Well Sample of Respondents of NSDUH 2019 Speak English", xlab="Categories", ylab="Number of Respondents"  )
```

Most participants speak English very well, very few speak well and almost none speak not well or none at all. If this survey was only given out in English, this distribution makes sense. But in the US population, while the majority of people speak English, many do not speak it "very well."

__Are there more English speaker female or males?__

```{r}
counts <- table(dat$irsex, dat$speakengl)
barplot(counts, main= "How Well Sample of Respondents of NSDUH 2019 Speak English Seperated by Gender", xlab="Categories", ylab="Number of Respondents" )


```

There are a similar number of males and females who speak English "very well" There are many more females who speak English "Well," so overall there are more females then males who speak English. 
  
  
# Exam 1

Date:

## Instructions

a. Create a folder in your computer (a good place would be under Crim 250, Exams). 

b. Download the dataset from the Canvas website (fatal-police-shootings-data.csv) onto that folder, and save your Exam 1.Rmd file in the same folder.

c. Download the README.md file. This is the codebook. 

d. Load the data into an R data frame.
```{r}
dat <- read.csv(file = 'fatal-police-shootings-data.csv')

head(dat)
```


## Problem 1 (10 points)

### a.Describe the dataset.
This is the source: https://github.com/washingtonpost/data-police-shootings. Write two sentences (max.) about this.

This data set is data collected by the Washington Post. It gives information about how many fatal shootings there were by an active duty police officer, and gives details about the victim (example: armed or unarmed.)

### b. How many observations are there in the data frame?
```{r}
nrow(dat)

```
There are 6594 observations in the data frame.

### c. Look at the names of the variables in the data frame. Describe what "body_camera", "flee", and "armed" represent, according to the codebook. Again, only write one sentence (max) per variable.
```{r}
names(dat)
```

"Body_camera" indicates whether or not  the officer was wearing a body camera that may have recorded part of the incident.
"flee" represents whether or not the victim was moving away from the officers and how they fled.
"armed" represents whether or not the victim was armed with something the officers belived could inflict harm and specifies what, if anything, the victims were carrying.

### d. What are three weapons that you are surprised to find in the "armed" variable? Make a table of the values in "armed" to see the options.
```{r}
table(dat$armed)

```

I was surprised to find binoculars, air conditioners and a motorcycle, because these are not things that I would typically think of as weapons. I wonder who determined that these items were a threat. 

## Problem 2 (10 points)

### a. Describe the age distribution of the sample. Is this what you would expect to see?
```{r}
hist(dat$age, main= "Frequency of ages of police shooting victims from Washington Post Data", xlab = "Ages of victims" )
```

The age distribution is right skewed. This means that most of the victims were younger (20-40) This is what I would expect to see, because police shootings typically happen to people who police "perceive as threats" and very old people typically wont be seen as threats.  

### b. To understand the center of the age distribution, would you use a mean or a median, and why? Find the one you picked.
```{r}
counts <- table(dat$age)

median(counts)

```

Because this data is right skewed I used a median to find the center of age distribution. Outliers can have more of an impact on the mean, which would not make it as useful as a statistician.

### c. Describe the gender distribution of the sample. Do you find this surprising?
```{r}
table(dat$gender)

```

The gender distribution is not even. There are far more men then women. This makes sense because police usually perceive men as more of a threat than women. Additionally, men are arrested more than women overall according to the FBI.


## Problem 3 (10 points)

### a. How many police officers had a body camera, according to news reports? What proportion is this of all the incidents in the data? Are you surprised that it is so high or low?

```{r}
table(dat$body_camera)


sum(table(dat$body_camera))

 5684/6594

```

There are many more people who were not wearing body cams then people who were. There were 5684 people not wearing body cams out of the 6594 recorded, which means 86.2 percent of officers did not have their cameras on. I would think that there would be more people wearing body cams in data recorded since 2015, because there has been a big push for more body cams in the recent years. However, many police officers do not turn on their body cameras.

### b. In  how many of the incidents was the victim fleeing? What proportion is this of the total number of incidents in the data? Is this what you would expect?
```{r}
table(dat$flee)

1058 + 845 + 3952 + 248

(1058 + 845 + 248)/6103
```

There are 491 pieces of missing data I excluded these from my calculations. I assume this means that the people who collected the data do not know whether the victims fled, but they did not make it clear. Additionally, I am assuming that "other" means people who fled in a different way then car or foot. There are a total of 6103 pieces of data (minus the data that was missing) and there are 845 people who fled on foot, 1058 by car and 248 by other. This means that only 35 percent of victims attempted to flee. I would expect it to be more, because police officers should not have to shoot people who are not fleeing. At the same time, if a victim is fleeing they may not be an imminent danger to a police officer (because they are running, not attacking), so it is possible the officers wouldn't shoot.


## Problem 4 (10 points) -  Answer only one of these (a or __b__).

a. Describe the relationship between the variables "body camera" and "flee" using a stacked barplot. What can you conclude from this relationship? 

*Hint 1: The categories along the x-axis are the options for "flee", each bar contains information about whether the police officer had a body camera (vertically), and the height along the y-axis shows the frequency of that category).*

*Hint 2: Also, if you are unsure about the syntax for barplot, run ?barplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.*


```{r}

```

__Your answer here.__

### b. Describe the relationship between age and race by using a boxplot. What can you conclude from this relationship? 

*Hint 1: The categories along the x-axis are the race categories and the height along the y-axis is age.* 

*Hint 2: Also, if you are unsure about the syntax for boxplot, run ?boxplot in R and see some examples at the bottom of the documentation. This is usually a good way to look up the syntax of R code. You can also Google it.*


```{r}
table(dat$race)

plot(factor(dat$race), dat$age, main= "Barplot of Age of Victims and Race",xlab= "Race in Catagories", ylab= "Age of victims",
     names=c("unkown","Asian","Black","Hispanic","NA ","Other","White"))



```

NOTE there is missing data. The first bar plot represents "unknown" data. Black= Black Non-Hispanic, White= White, non-Hispanic, NA= Native American

There is a clear distinction between the median age victims who are white and every other race (excluding unknown). The median age of victims who are white are much higher than the median age of victims of the other races. Additionally, the ages of white victims are much more evenly dispered. The box is close to the middle which shows a more even dispersion, and the box is longer which shows more dispersed data within Q2 and Q3. Native Americans and black victims have the lowest median age, although there are many outliers who are black. This data shows that victims or color tend to be younger than white victims of police shootings. 




## Extra credit (10 points)

### a. What does this code tell us? 

```{r, eval=FALSE}
mydates <- as.Date(dat$date)
head(mydates)
(mydates[length(mydates)] - mydates[1])

2458/365

```

This code tells us the number of days of data we have. The data has been being kept since 2015, and it is now 2021. So it makes sense that the data is of 2458 says (6.7 years)

### b. On Friday, a new report was published that was described as follows by The Guardian: "More than half of US police killings are mislabelled or not reported, study finds." Without reading this article now (due to limited time), why do you think police killings might be mislabelled or underreported?

It seems that police killings are underreported in federal data bases. According to the Washington Post Study, the FBI and CDC does not log as many fatal shootings as there actually are. Police killings are most likely under reported because it is a liability to police forces when one of their officers shoots and kills a victim. Additionally, as this data shows, minority victims tend to be younger, which demonstrates possible racial prejudice. Police killings are most likely misreported because people may blame death on other factors than a gun wound. If the cause of death is reported differently, then a victim would not be counted towards a police shooting death.

### c. Regarding missing values in problem 4, do you see any? If so, do you think that's all that's missing from the data?

In problem 4 the missing value is an unknown race. This differs from the race catagory of 'other,' which shows victims who do not identify as one of the specific racial categories laid out by the Washington Post. I assume that there is much more information missing in general. There is missing data about whether victims fled. There are probably many missing values of signs of mental illness, because that is not easy data to collect. Additionally, the data that the Washington Post collected is from many different sources, none of which have all the pieces data they wish to collect. Overall, there is probably a lot of data and variables missing that are important to understanding the full scope of the circumstances of the shooting. This data just shows us a very small lens of information.

# Assignment 3

---
title: "Assignment 3"
author: "Niko Amber"
date: 10/28/2021'
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


I worked with Bella Werneck

This assignment is due on Canvas on Wednesday 10/27/2021 before class, at 10:15 am. Include the name of anyone with whom you collaborated at the top of the assignment.

Submit your responses as either an HTML file or a PDF file on Canvas. Also, please upload it to your website.

Save the file (found on Canvas) crime_simple.txt to the same folder as this file (your Rmd file for Assignment 3).

Load the data.
```{r}
library(readr)
library(knitr)
dat_crime <- read_delim("/Users/nikoamber/Library/Mobile Documents/com~apple~CloudDocs/Penn/Freshman Fall/Criminology/Test Github/crime_simple.txt", delim = "\t")

```

This is a dataset from a textbook by Brian S. Everitt about crime in the US in 1960. The data originate from the Uniform Crime Report of the FBI and other government sources. The data for 47 states of the USA are given. 

Here is the codebook:

R: Crime rate: # of offenses reported to police per million population

Age: The number of males of age 14-24 per 1000 population

S: Indicator variable for Southern states (0 = No, 1 = Yes)

Ed: Mean of years of schooling x 10 for persons of age 25 or older

Ex0: 1960 per capita expenditure on police by state and local government

Ex1: 1959 per capita expenditure on police by state and local government

LF: Labor force participation rate per 1000 civilian urban males age 14-24

M: The number of males per 1000 females

N: State population size in hundred thousands

NW: The number of non-whites per 1000 population

U1: Unemployment rate of urban males per 1000 of age 14-24

U2: Unemployment rate of urban males per 1000 of age 35-39

W: Median value of transferable goods and assets or family income in tens of $

X: The number of families per 1000 earning below 1/2 the median income


We are interested in checking whether the reported crime rate (# of offenses reported to police per million population) and the average education (mean number of years of schooling for persons of age 25 or older) are related. 


__1. How many observations are there in the dataset? To what does each observation correspond?__

```{r}
nrow(dat_crime)
ncol(dat_crime)
summary(dat_crime)
head(dat_crime)

```

There are 47 observations in the data frame. Each row gives the data for each of the 47 states included in this data set. Each of the 47 rows includes data from each state which gives information about the 14 variables explained in the code book.

out 4 variables of data from each state including, level of education, age and whether or not the states are in the South.

__2. Draw a scatterplot of the two variables. Calculate the correlation between the two variables. Can you come up with an explanation for this relationship?__

```{r, fig.width=6, fig.height=4}
plot(dat_crime$Ed, dat_crime$R, xlab= "Average Years of Schooling x 10 for people over 25", ylab= "Crime Rate per state According to 1960 UCR Data", main = "Relationship between Level of Education and Crime Rate for 47 states in 1960 ")

head(dat_crime)
cor(dat_crime$Ed, dat_crime$R)
```

The correlation efficient is .3228349 which indicates a slight positive relationship between crime rate and level of education. This is not what I would have expected. It is important to note this is correlation not causation, so higher levels of education do not result in more crime. This data includes all crime types. It is possible that there area lot of white collar criminals which typically  that the criminals have higher levels of education. Additionally this data is based on the crime reported, not all crime that has happened which could have an impact on the corelation. The correlation is not strong, but I would like to know why there is a positive correlation at all.

__3. Regress reported crime rate (y) on average education (x) and call this linear model `crime.lm` and write the summary of the regression by using this code, which makes it look a little nicer `{r, eval=FALSE}  summary(crime.lm)$coef, digits = 2)`.__

```{r,} 

lm( formula = dat_crime$R ~ dat_crime$Ed, data = (dat_crime) )

lmCrime  <- lm( formula = dat_crime$R ~ dat_crime$Ed, data = (dat_crime) )
summary(lmCrime)
coef(lmCrime, digit = 2)
```

__4. Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.)__

```{r} 

plot(dat_crime$Ed, lmCrime$residuals, main= "Residuals vs. X", xlab = "x, Average Years of Schooling x 10 per People Over 25", ylab = "Residuals" )
abline(h = 0, lty = "dashed")


```
The linearity assumption is satisfied because the residuals vs X plot does not have a pattern around the horizontal line y=0.

```{r} 

plot(lmCrime, which = 1)

```
The independent assumption is satisfied because not only does the residuals vs X plot not have a pattern around the horizontal line x, also the residuals vs fitted shows no pattern.

```{r} 

plot(lmCrime, which = 3)

```

The equal variance assumption helps us analyze the homoskedasticity assumption, which is satisfied because the red line is close to being horizontal.

```{r}
plot(lmCrime, which=2)

```
The normal QQ plot tells us that the normal population is slightly right skewed, there is a light tail, which means the distribution isn't normal.

__5. Is the relationship between reported crime and average education statistically significant? Report the estimated coefficient of the slope, the standard error, and the p-value. What does it mean for the relationship to be statistically significant?__

```{r}
summary(lmCrime)

```

The p value is less than 0.05 so the relationship between reported crime and average education is stastistically significant. A relationship is statistically significant when you can reject the null hypothesis. 


__6. How are reported crime and average education related? In other words, for every unit increase in average education, how does reported crime rate change (per million) per state?__

For every unit increase in average education, the crime rate changes 1.1161 per million per state.

__7. Can you conclude that if individuals were to receive more education, then crime will be reported more often? Why or why not?__

No. Correlation does not mean causation. Just because there seems to be a positive corelation between level of education and reported crime rates, does not mean that more education CAUSES more crime.

# Exam 2

---
title: "Exam 2"
author: "Niko Amber"
date: "11/01/2021"
output:
  html_document: default
  pdf_document: default
---


a. Create a folder in your computer (a good place would be under Crim 250, Exams). 

b. Download the dataset from the Canvas website (sim.data.csv) onto that folder, and save your Exam 2.Rmd file in the same folder.

c. Data description: This dataset provides (simulated) data about 200 police departments in one year. It contains information about the funding received by the department as well as incidents of police brutality. Suppose this dataset (sim.data.csv) was collected by researchers to answer this question: **"Does having more funding in a police department lead to fewer incidents of police brutality?"**
d. Codebook:
- funds: How much funding the police department received in that year in millions of dollars.
- po.brut: How many incidents of police brutality were reported by the department that year.
- po.dept.code: Police department code

__Problem 1: EDA (10 points)__

Describe the dataset and variables. Perform exploratory data analysis for the two variables of interest: funds and po.brut.

```{r}
dat <- read.csv(file = "/Users/nikoamber/Library/Mobile Documents/com~apple~CloudDocs/Penn/Freshman Fall/Criminology/Test Github/sim.data.csv")

names(dat)

summary(dat)

nrow(dat)
ncol(dat)

head(dat)

hist(dat$funds, main="Histogram of Funds Recived by Police Department (in millions)", xlab= "Amount of funds in millions")

hist(dat$po.brut, main="Histograms of instances of Police Brutality recorded in a year", xlab= "Recorded instances of Police Brutality")

plot(dat$funds, dat$po.brut, main = "Plot of Funds vs Instances of Police Brutality", xlab = "Funds in millions ", ylab = "Recorded instances of Police Brutality")

cor(dat$funds, dat$po.brut)

```

There are 200 observations in this data set which is based on simulated information. There are 3 different variables: funds-the amount of funds the police department receive in a year (in millions), po.brut- how many incidents of police brutality were reported in that year, and po.dept.code- which is the police department code. 

The mean funds (in millions) received by one of the 200 police departments is 61.04 and the median is 59.75. The mean incidences of police brutality recorded is 18.14 and the median is 19.00.

Both funding and number of recorded instances of police brutality are numeric variables. When looking at the histogram of both variables they look normally distributed. Recorded instances of police brutality looks slightly left skewed, although the data set is small so it might not matter.

The plot of funds vs instances looks to have a linear relationship

__Problem 2: Linear regression (30 points)__

_a. Perform a simple linear regression to answer the question of interest. To do this, name your linear model "reg.output" and write the summary of the regression by using "summary(reg.output)"._

```{r}

reg_output <- lm(formula = po.brut ~ funds, data = dat)

summary(reg_output)
```


_b. Report the estimated coefficient, standard error, and p-value of the slope. Is the relationship between funds and incidents statistically significant? Explain._

The estimated coefficient is -0.367099, the standard error is 0.282503, and the p-value of the slope is 2.2e-16. The p value is significantly lower that 0.05 so the relationship between funds and instances of police brutality is statistically significant. The null hypothesis is rejected. 

_c. Draw a scatterplot of po.brut (y-axis) and funds (x-axis). Right below your plot command, use abline to draw the fitted regression line, like this:_

```{r, fig.width=4, fig.height=4,}

plot( dat$funds, dat$po.brut, main = "Plot of Funds vs Instances of Police Brutality", xlab = "Funds in millions ", ylab = "Recorded instances of Police Brutality")
abline(reg_output, col = "red", lwd=2)

```
__Does the line look like a good fit? Why or why not?__

This line seems to be a good fit, there are some points that are off the line. There does not look to be any extreme outliers. There is a negative correlation between funds and number of instances of police brutality, meaning for lower funds instances of police brutality go down on average, which makes sense because the correlation coefficient is negative. It is important to note that this is a correlation not a causation.

__d. Are the four assumptions of linear regression satisfied? To answer this, draw the relevant plots. (Write a maximum of one sentence per assumption.) If not, what might you try to do to improve this (if you had more time)?__

```{r}
plot(dat$funds, reg_output$residuals, main= "Residuals vs. X", xlab = "x, Amount of Police funding in millions", ylab = "Residuals" )
abline(h = 0, lty = "dashed")

plot(reg_output, which = 1)


```
The linearity assumption is not satisfied. There looks to be a pattern around the horizontal line Y=0. There seems to be a curved line. The residuals vs fitted line also has a clear curved line going through the data, rather than flat which further proves the linearity assumption is not satisfied.

```{r}
plot(dat$funds, reg_output$residuals, main= "Residuals vs. X", xlab = "x, Amount of Police funding in millions", ylab = "Residuals" )
abline(h = 0, lty = "dashed")
```
The independence assumption is not satisfied because there is a clear pattern when plotting the residuals vs X. This most likely means that this is not a random data set.

```{r}
plot(reg_output, which= 3)
```

The equal variance assumption is not satisfied. There is a clear trend to the line of this plot, which means that the residuals has a non-constant variance. This means that the data is not homoscedastic, which you can further prove because on the scale location plot the points tend to cluster in one part of the plot.

```{r}
plot(reg_output, which = 2)
```

The normal qq plot tells us that the population in this data set is skewed left, meaning the distribution isn't normal.


If I had more time, I would explore other ways to analyze the data. Perhaps there is not a linear relationship.

__e. Answer the question of interest based on your analysis.__

The question of interest **"Does having more funding in a police department lead to fewer incidents of police brutality?"** is unable to be answered given the data provided. Although the initial scatter plot seems to have a line that is straight, upon further analysis it is clear the assumptions of linear regression are not satisfied. Because of this, we cannot make inferences based on this data.

__Problem 3: Data ethics (10 points)__

Describe the dataset. Considering our lecture on data ethics, what concerns do you have about the dataset? Once you perform your analysis to answer the question of interest using this dataset, what concerns might you have about the results?

I have concerns about the assumptions that would be made from this data set. The questions the researchers are asking could have serious implications for police departments and their funding, and using this small sample of data is not enough to make an inference. 

It is important to note that the data is from only 200 police stations. This is not enough data to make any inferences. This data should have been taken from all of the police stations. We also do not know which police stations this data was taken from. According to the residuals vs X plot, it is possible that the data set is not random.

It is unethical for this data to be cherry picked, but it is not stated that the data included is random. It should be considered who picked to include this data in the set.

The data does not take into account other factors including who decided to report this information.

If a police department just looks at the scatterplot of the x and y variables, it looks as though there is a linear correlation, and the p value is below 0.05 which would mean that the null hypothesis is rejected. One may read this data and __assume__ that as funding increases, instances of police brutality would go down. Police departments might use this inference to decide the best way to stop police brutality would be to increase funding.

Additionally, all of the assumptions of linear regression are not satisfied, which means you cannot trust the linear relationship found by the scatterplot graph of funds and instances of police brutality.

# Assignment 4

## Learning about gg plot

### _basics_


```{r}
library(tidyverse)

```
I installed a new package from the library. You only have to install it once, but you have to reload everytime you use it in a new session.

```{r}
head(mpg)


```
This is the data set mpg which is given to us by ggplot2.
```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy))
```
First I used ggplot(data = mpg) to make a wmpty graph. To add to the graph first you go gemo_point which adds layers. Then you have to add mapping with aes to give the Y and X axis variables Afrom the data set.

```{r}
#ggplot(data = mpg) + 
  #<GEOM_FUNCTION>(mapping = aes(<MAPPINGS>))
# +ggtible
# +labs
```
This is a blank template to use to create a graph in ggplot2. To add titles and axis names add 
+tit
### _aesthetics_

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, color = class))
```
You can add a third varibale to a two dementional plot. In this case we added the third variable and made it differentiated by color. This plot will also add a legend, you can label the legend by saying +labs(color= "title")

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, size = class))
#> Warning: Using size for a discrete variable is not advised.

# Left
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, alpha = class))

# Right
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy, shape = class))

```

There are other aesthetics you can change the third variable with on a ggplot graph. Above there is alpha, which is transparency, shape, which changes the shape, and size. 

NOTE: ggplot2 will only use up to six shapes.

### _Subplots_

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_wrap(~ class, nrow = 2)
```
Facets break down plots to single variables. You have to use a discrete variable. you use facet_wrap() followed by a formula which starts with ~. In this graph, we used the class of car, same as above but seperated the cars. 

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy)) + 
  facet_grid(drv ~ cyl)

?mpg
```
This function plotted two different variables on a grid. 

### _Geometric Objects_

The different visual objects that ggplot2 uses are called geoms. 

There are different geoms that will create different types of graphs,  geom_point makes scatter plots, geom_smooth makes lines.

```{r}
ggplot(data = mpg) + 
  geom_smooth(mapping = aes(x = displ, y = hwy, linetype = drv))
```

Just like you can change the shape of a point on a scatter plot, you can change the type of line using geom_smooth. If you add another variable, in this case drv, you can make the new variable show different lines. 

```{r}
ggplot(data = mpg, mapping = aes(x = displ, y = hwy)) + 
  geom_point(mapping = aes( color = class))+ 
  geom_smooth(color = "red")
```
You can also use multiple geoms on one graph. This one has point and smooth.

```{r}
ggplot(data = diamonds) +
geom_bar(mapping = aes(x = cut ))
```

This ia a bar chart made with ggplot. The labels are automatic from the data set. If you want to change them, you have to use tribble.

```{r}
demo <- tribble(
  ~cut,         ~freq,
  "Fair",       1610,
  "Good",       4906,
  "Very Good",  12082,
  "Premium",    13791,
  "Ideal",      21551
)

#the section above identifies things

ggplot(data = demo) +
  geom_bar(mapping = aes(x = cut, y = freq), stat = "identity")


ggplot(data = diamonds) + 
  stat_summary(
    mapping = aes(x = cut, y = depth),
    fun.min = min,
    fun.max = max,
    fun = median
  )
```

### _Adding color to par charts_
```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, colour = cut))
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = cut))
```

Fill is a good way to add color

```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity))
```
 you can also add other variables when you want to add more color. 

```{r}
ggplot(data = diamonds, mapping = aes(x = cut, fill = clarity)) + 
  geom_bar(alpha = 1/5, position = "identity")
ggplot(data = diamonds, mapping = aes(x = cut, colour = clarity)) + 
  geom_bar(fill = NA, position = "identity")
```

the "identity" places the objects where they fall in the graph. Sometimes this means you have to make the bars more transparent using alpha. 

```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "fill")
```

The position = fill makes each stack of bars the same height. This is usefull to see the relationship between things. 

```{r}
ggplot(data = diamonds) + 
  geom_bar(mapping = aes(x = cut, fill = clarity), position = "dodge")
```

Position = dodge puts overlapping objects beside each other

```{r}
ggplot(data = mpg) + 
  geom_point(mapping = aes(x = displ, y = hwy), position = "jitter")
```

Position= jitter this adds random noise to each point. Adding randomness to your plot makes it more appealing at large scales.

### _Coordinate Systems_

The default coordinate system in ggplot is cartesian (x,y) sometimes it is useful to change it.

```{r}
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot()
ggplot(data = mpg, mapping = aes(x = class, y = hwy)) + 
  geom_boxplot() +
  coord_flip()
```

This switches the x and y axis. This is helpful is you want horizontal barplots. 
```{r}
nz <- map_data("nz")

ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black")

ggplot(nz, aes(long, lat, group = group)) +
  geom_polygon(fill = "white", colour = "black") +
  coord_quickmap()
```

coord_quickmap() sets the aspect ratio correctly for maps

```{r}
bar <- ggplot(data = diamonds) + 
  geom_bar(
    mapping = aes(x = cut, fill = cut), 
    show.legend = FALSE,
    width = 1
  ) + 
  theme(aspect.ratio = 1) +
  labs(x = NULL, y = NULL)

bar + coord_flip()
bar + coord_polar()
```

This uses polar coordinates

### __General ggplot format__

ggplot(data = <DATA>) + 
  <GEOM_FUNCTION>(
     mapping = aes(<MAPPINGS>),
     stat = <STAT>, 
     position = <POSITION>
  ) +
  <COORDINATE_FUNCTION> +
  <FACET_FUNCTION>
  
### _Labeling in ggplot_

```{r}
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Fuel efficiency generally decreases with engine size",
    subtitle = "Two seaters (sports cars) are an exception because of their light weight",
    caption = "Data from fueleconomy.gov"
  )
```

In EDA it is important to label your data. the labs function adds titles. You can also add subtitles and captions, which go at the bottom of the plot.

```{r}
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_smooth(se = FALSE) +
  labs(
    x = "Engine displacement (L)",
    y = "Highway fuel economy (mpg)",
    colour = "Car type"
  )
```

The labs function can also be used to change the x and y axis variable names. 

```{r}
df <- tibble(
  x = runif(10),
  y = runif(10)
)
ggplot(df, aes(x, y)) +
  geom_point() +
  labs(
    x = quote(sum(x[i] ^ 2, i == 1, n)),
    y = quote(alpha + beta + frac(delta, theta))
  )
```

You can alternatively use math equations instead of labels. To find them look up ?plotmath

```{r}
best_in_class <- mpg %>%
  group_by(class) %>%
  filter(row_number(desc(hwy)) == 1)
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(colour = class)) +
  geom_label(aes(label = model), data = best_in_class, nudge_y = 2, alpha = 0.5)
```

### _annotations_

It is also useful to add annotations to EDA. geom_point() is a way to add text to your graphs. Using nudge_y, you move the labels up a bit so it doesn't cover the data, alpha makes the labels see through.

```{r}
best_in_class <- mpg %>%
  group_by(class) %>%
  filter(row_number(desc(hwy)) == 1)

class_avg <- mpg %>%
  group_by(class) %>%
  summarise(
    displ = median(displ),
    hwy = median(hwy)
  )
#> `summarise()` ungrouping output (override with `.groups` argument)

ggplot(mpg, aes(displ, hwy, colour = class)) +
  ggrepel::geom_label_repel(aes(label = class),
    data = class_avg,
    size = 6,
    label.size = 0,
    segment.color = NA
  ) +
  geom_point() +
  theme(legend.position = "none")
```

This code removes the legend and puts the label directly on the graph.


```{r}
label <- mpg %>%
  summarise(
    displ = max(displ),
    hwy = max(hwy),
    label = "Increasing engine size is \nrelated to decreasing fuel economy."
  )

ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  geom_text(aes(label = label), data = label, vjust = "top", hjust = "right")
```

In order to add a single label to the plot, you have to make a data frame. In order for the label to be in the corner, just use the maximin x and y values.

### _Changing the Axis_

```{r}
ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  scale_y_continuous(breaks = seq(15, 40, by = 5))

ggplot(mpg, aes(displ, hwy)) +
  geom_point() +
  scale_x_continuous(labels = NULL) +
  scale_y_continuous(labels = NULL)
```

It is possible to change the distance between ticks on the graph. Alternatively, using null, you can remove labels completely. 

### _Color_

The R brewer color package provides a good set of colors to use. 

```{r}
ggplot(mpg, aes(displ, hwy)) +
  geom_point(aes(color = drv, shape = drv)) +
  scale_colour_brewer(palette = "Set1")
```
```{r}
presidential %>%
  mutate(id = 33 + row_number()) %>%
  ggplot(aes(start, id, colour = party)) +
    geom_point() +
    geom_segment(aes(xend = end, yend = id)) +
    scale_colour_manual(values = c(Republican = "red", Democratic = "blue"))
```

This allows you to add certain colors to certain data.

### _Zooming_

```{r}
ggplot(mpg, mapping = aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth() +
  coord_cartesian(xlim = c(5, 7), ylim = c(10, 30))

mpg %>%
  filter(displ >= 5, displ <= 7, hwy >= 10, hwy <= 30) %>%
  ggplot(aes(displ, hwy)) +
  geom_point(aes(color = class)) +
  geom_smooth()
```

coord_cartesian() allows you to zoom into plots. You can also set limits. 

You can also add themes and other colors by installing other packages.

# Final Write Up

University of Pennsylvania

Andrew Santillan, Isabella Werneck, Kaiyla Jolley, and Niko Amber

December 12th, 2021

## _1. Introduction_


Following Donald Trump's presidential election in 2016, there has been a substantial increase in hate crimes in the United States. According to the FBI's report on hate crime statistics, hate crimes have increased from 6,121 incidents in 2016 to 7,314 in 2019—a 19.49 percent increase in only 3 years (FBI, 2019). This spike in hate crimes is commonly associated with Trump's inflammatory rhetoric during his political campaign and his subsequent win in the 2016 elections (Edwards & Rushin, 2018). Critics say that his victory emboldened hate crime perpetrators, which led to an increase in hate crimes. This was dubbed as the "Trump Effect" (Edwards & Rushin, 2018). 
Data shows that anti-immigrant sentiment, racism, and sexism are common among Trump's supporters (Sharffner et al, 2018), which may suggest that they are more likely than non-supporters to commit hate crimes against minority groups. In this report, we analyze the correlation between states' political leaning in the 2020 elections and the associated hate crime rates in 2021. The data used in this report contains voting results per state from the 2020 elections and hate crime numbers per state in 2019, which is divided into six bias categories. 

### _1.1 Research Question and Hypothesis_

Our research question is the following: Is there a relationship between a state’s political affiliation in the 2020 Presidential election and hate crime data as reported to the FBI? Following the assumption that individuals who voted for Trump are more likely to commit a hate crime, we expect to find that states that mostly voted Republican in 2020 had higher hate crime rates in 2019

## _2 Exploratory Data Analysis_

### _2.1 Data Description_

The dataset in this report contains data from the FBI 2019 Hate Crime Statistics (FBI, 2019) and from the Official 2020 Presidential General Election Results (FEC, 2021). The hate crime data was collected through the Uniform Crime Reporting (UCR) Program and it includes both single-bias and multiple-bias hate crimes. The synthesized dataset contains 50 observations and 14 variables. Six of the variables correspond to the hate crime categories, which include the following biases: race, religion, sexual orientation, disability, gender, and gender identity. 

### _2.2 Missing Values_

Only 49 American states were included in the observations. Alabama did not report to the UCR Program, and so it was excluded from the dataset. Washington D.C. reported to the UCR as a separate entity, and so it was included as a separate observation. 
It is important to note that participation in the Federal UCR Program Initiative is voluntary, which means that state jurisdictions can choose not to report. In the case of Alabama, the entire state chose not to participate in the UCR Program, but for all other states there are jurisdictions missing from the dataset. Therefore, there is a distinction between total state population and population covered. The term "population covered" means the total population covered by the jurisdictions that chose to report. For example, the total population of Florida is 21.5 million, and the population covered is approximately 20.9 million. Due to the voluntary nature of the UCR Program, there are many missing values in the dataset.

### _2.3 Percentage of population that reported to the FBI_


```{r }
dat <- read.csv(file = "/Users/nikoamber/Library/Mobile Documents/com~apple~CloudDocs/Penn/Freshman Fall/Criminology/Final Data - Final Project Data with Rates.csv")
library(tidyverse)

library(usmap)

plot_usmap(data = dat, values = "pop_rat") +
   scale_fill_continuous( low = "white", high = "navy", 
                         name = "Population Reported", label = scales::comma
  )


```
### _2.4 Total hate crime per state_

```{r}

plot_usmap(data = dat, values = "rate") +
   scale_fill_continuous( low = "navy", high = "white", 
                         name = "Rate of Hate Crimes", label = scales::comma
  )


```



### _2.5 Codebook_

pop_cov: Population covered by FBI
pop_tot: Total state population
pop_rat: Population covered by FBI/total state population
perc_rep: Percentage of population that voted for Trump
perc_dem: Percentage of population that voted for Biden
rep_dem: Republican (R)
rate: Number of hate crimes reported per 100,000
Rate_rea: number of racially motivated hate crime per 100,000
Rate_rel: number of hate crimes against religion per 100,000
Rate_sex: number of hate crimes against sexual orientation per 100,000
Rate_dis: number of hate crimes against disabilities per 100,000
Rate_gen: number of hate crimes against gender per 100,000
Rate_gei: number of hate crimes against gender identity per 100,000

## _2.6 Scatterplots_

*Note: We have labelled significant outlines to facilitate visial analysis.*

*Please see codebook for variable names*

__Percentage that Voted Republican vs. Rate of Total Hate Crime__

```{r}
# rate Hate Crimes vs. Political Affiliation
scatter.smooth(
  x=dat$perc_rep,
  xlab="Percentage Republican",
  y=dat$rate,
  ylab="rate Hate Crimes Reported (per 100,000)",
  main="rate Hate Crimes vs. Political Affiliation"
)

text(
  x=c(5.40),
  y=c(31.464),
  labels=c("D.C."),
  pos=1
)
```

__Percentage that Voted Republican vs. Rate of Race/Ethnicity Hate Crime__


```{r}
# rate_rea Hate Crimes vs. Political Affiliation
scatter.smooth(
  x=dat$perc_rep,
  xlab="Percentage Republican",
  y=dat$rate_rea,
  ylab="rate_rea Hate Crimes Reported (per 100,000)",
  main="rate_rea Hate Crimes vs. Political Affiliation"
)

text(
  x=c(5.40),
  y=c(16.86),
  labels=c("D.C."),
  pos=1
)

```

__Percentage that Voted Republican vs. Rate of Religion Hate Crime__

```{r}
# rate_rel Hate Crimes vs. Political Affiliation
scatter.smooth(
  x=dat$perc_rep,
  xlab="Percentage Republican",
  y=dat$rate_rel,
  ylab="rate_rel Hate Crimes Reported (per 100,000)",
  main="rate_rel Hate Crimes vs. Political Affiliation"
)

text(
  x=c(5.40, 41.4, 37.75),
  y=c(1.134, 2.894, 1.884),
  labels=c("D.C", "New Jersey", "New York"),
  pos=c(3, 1, 1)
)
```

__Percentage that Voted Republican vs. Rate of Sexual Orientation Hate Crime__

```{r}
# rate_sex Hate Crimes vs. Political Affiliation
scatter.smooth(
  x=dat$perc_rep,
  xlab="Percentage Republican",
  y=dat$rate_sex,
  ylab="rate_sex Hate Crimes Reported (per 100,000)",
  main="rate_sex Crimes vs. Political Affiliation"
)

text(
  x=c(5.40),
  y=c(9.21),
  labels=c("D.C."),
  pos=1
)
```

__Percentage that Voted Republican vs. Rate of Disability Hate Crime__

```{r}
# rate_dis Hate Crimes vs. Political Affiliation
scatter.smooth(
  x=dat$perc_rep,
  xlab="Percentage Republican",
  y=dat$rate_dis,
  ylab="rate_dis Hate Crimes Reported (per 100,000)",
  main="rate_dis Hate Crimes vs. Political Affiliation"
)

text(
  x=c(5.40, 57.60, 53.27),
  y=c(0.142, 0.680, 0.565),
  labels=c("D.C.", "Mississippi", "Ohio"),
  pos=c(3, 1, 1)
)
```

__Percentage that Voted Republican vs. Rate of Gender Hate Crime__

```{r}
# rate_gen Hate Crimes vs. Political Affiliation
scatter.smooth(
  x=dat$perc_rep,
  xlab="Percentage Republican",
  y=dat$rate_gen,
  ylab="rate_gen Hate Crimes Reported (per 100,000)",
  main="rate_gen Hate Crimes vs. Political Affiliation"
)

text(
  x=c(5.40, 47.84),
  y=c(0.283, 0.151),
  labels=c("D.C.", "Michigan"),
  pos=c(1, 1)
)
```

__Percentage that Voted Republican vs. Rate of Gender Identity Hate Crime__

```{r}
# rate_gei Hate Crimes vs. Political Affiliation
scatter.smooth(
  x=dat$perc_rep,
  xlab="Percentage Republican",
  y=dat$rate_gei,
  ylab="rate_gei Hate Crimes Reported (per 100,000)",
  main="rate_gei Hate Crimes vs. Political Affiliation"
)

text(
  x=c(5.40),
  y=c(3.826),
  labels=c("D.C."),
  pos=1
)
```

## _3 Modeling the Data and Diagnostics_

To answer our research question, we performed linear regressions on each of the seven categories of hate crimes that the FBI collects data for. A linear regression will allow us to see if there is an association between an increase in Trump voters and incidents of hate crimes. We performed individual regressions to see if any of the categories had a different trend or significance level. We know that breaking down the categories will make our sample smaller so our linear regression models for the specific categories will not be as strong or reliable as the linear regression for total hate crime rate. 

## _3.1 Assumptions_

```{r}
reg.output.total <- lm(formula = rate ~ perc_rep, data = dat) 
summary(reg.output.total)
```

```{r}
length(dat$perc_rep)
length(reg.output.total$residuals)
plot(dat$perc_rep, reg.output.total$residuals, ylim=c(-15,15), main="Residuals vs. x", xlab="x, Proportion of Republican Voters", ylab="Residuals")
abline(h = 0, lty="dashed")
```

__Figure 3.11__

```{r}
plot(reg.output.total, which=1)
```

__Figure 3.12__

```{r}
plot(reg.output.total, which=3)
```

__Figure 3.13__

```{r}
plot(reg.output.total, which=5)
```
__Figure 3.14__

```{r}
plot(reg.output.total, which=2)
```


Diagnostic plots for the linear regression model indicate that the four assumptions of linearity, independence, homoscedasticity, and normal population were not satisfied for any of the categories of hate crime that we analyzed. To explain the diagnostic plots, we will analyze the plots for the total hate crime rate. Fig 3.11 is the “Residuals vs x,” which shows that as the percentage of Trump voters increases, the value of the residuals also increases. Since this trend is a pattern, it does not satisfy the linearity assumption, which needs to show a “Residuals vs x” plot with no distinguishable pattern. Fig 3.12 is the “Residuals vs. Fitted” plot, which shows a red line that appears to have a negative linear trend, indicating that the linearity assumption is not satisfied since the average value of the residuals needs to be flat for a linear trend. There is no diagnostic plot for the independence assumption, but we can assume this assumption is satisfied because the data is not a time series, and there are no discernible signs of clumping in the plots. Fig 3.13 is the scale location plot for the homoscedasticity assumption. The red line in the plot shows an almost exponential trend which indicates that the residuals have non-constant variance. Therefore the homoscedasticity assumption is not satisfied. Fig 3.14 and Fig 3.15 are the “Residuals vs. Leverage” plots and the “Normal Q-Q” plots for the normal population assumption. The “Residuals vs Leverage” plot in Fig 3.14 indicates that point 50 (Washington D.C) is a significant outlier in the data set. Fig 3.15 is the normal q-q plot that shows an almost straight line, but the outlier pushes the trend to be slightly right-skewed. The normal population assumption is not satisfied due to the outlier at point 50, although the q-q plot is decent. The diagnostic plots for the other categories of hate crimes also follow similar trends, so we can conclude that the linear model is not a good analytic model for the data.

## _4 Results_

We observed statistically significant p-values at the 0.01 alpha level for all categories of hate crimes except in hate crimes pertaining to disabilities. This means that the association between hate crime rates and the percentage of Trump voters is not due to chance, and the null hypothesis could be rejected if the linear model were a good fit for the data. For the total hate crime rate, we observed a coefficient of -0.23276 which means that for every one percent increase in Trump supporters, there is a 0.23276 (with a standard error of 0.04208) decrease in total hate crimes per 100,000 people. We observed a negative coefficient for five hate crime categories, with race/ethnicity/ancestry-based hate crimes having the largest decrease of -2.9208 per 100,000 people. The disability category has a coefficient of 0.0003827 which means that for every one percent increase in Trump voters, there is an increase in the rate of hate crimes pertaining to disabilities by  0.0003827 per 100,000 people. However, this category had a p-value of 0.8, which is not statistically significant, so the association we see could be due to chance. All of the adjusted R-squared values we observed were under 0.5, which means that the model is not a good fit for the data because it cannot account for much of the variation in the data. Therefore, we cannot conclude an association between the percentage of Trump voters and the hate crime rate based on the linear model.

## _5 Discussion/analysis_

In our study, there were confounding variables that impacted our results. As shown in the DAG below, the two main confounding variables are non-voters and underreporting of crimes. 

![DAG](/Users/nikoamber/Library/Mobile Documents/com~apple~CloudDocs/Penn/Freshman Fall/Criminology/Final Project Write-Up.png)

Non-voters impacted our data in multiple ways. When we did our analysis and EDA, we only looked at members of the electorate who voted for the Republican and Democratic parties. We only performed our analysis using the percentage of Republican voters in the 2020 election. This means our analysis did not take into account constituents who voted for alternate parties. There were over 2,000,000 votes for third party and write in candidates (FEC, 2021).  Additionally, we did not account for non-voters in the U.S. Only 67% of eligible voters casted a ballot in the 2020 election (Fabina, 2021). We did not take into account residents and others who cannot vote. 

As mentioned above, reporting to the UCR is voluntary. More importantly, there is a large hate crime reporting gap (COPS Office, 2013). This works in many ways. First: surveys done by the US Department of Justice have uncovered that many people who are victims of hate crimes do not report. According to the DOJ, victims do not believe they will be aided by law enforcement.  Additionally, many crimes that are motivated by hate are not reported as such, as it is difficult for officers to discern whether a crime is motivated by hate. It is also much more work to convict and prove a crime was motivated by hate (Davis, 2021). According to the International Association of Police Chiefs, less than ⅔ of the over 250,000 hate crimes committed per year are reported (Davis, 2021). 

In the future research, we would look more closely at the gaps in hate crime reporting. Rather than analyzing the hate crime data, we would analyze the connection between states that voted majority Republican and the percentage of jurisdictions that reported. We would utilize linear regression again to establish if there is a causal relationship. A diff-in-diff model could also be interesting to analyze the "Trump Effect" on hate crime rates, but existing data might be insufficient for that. 

## _6 Bibliography_

COPS Office. (2013, May). Hate Crime Reporting – Working to Close the Gap. Retrieved from 
https://cops.usdoj.gov/html/dispatch/05-2013/hate_crime_reporting.asp

Davis, R. L. (2021). The Hate Crimes Reporting Gap: Low Numbers Keep Tensions High	 
Retrieved from https://www.policechiefmagazine.org/the-hate-crimes/

Fabina, J. (2021, April 29). Despite pandemic challenges, 2020 election had largest increase in 
voting between presidential elections on record. Retrieved from 
https://www.census.gov/library/stories/2021/04/record-high-turnout-in-2020-general-elec
tion.html

 Federal Bureau of Investigation. (2019, October 29). Incidents and offenses. Retrieved from 
https://ucr.fbi.gov/hate-crime/2019/topic-pages/incidents-and-offenses

Federal Election Commission. (2021, January 28). Official 2020 presidential general election 
results. Retrieved from 
https://www.fec.gov/resources/cms-content/documents/2020presgeresults.pdf

Rushin, S., & Edwards, G. S. (2018). The effect of president Trump's election on hate crimes. 
SSRN Electronic Journal. https://doi.org/10.2139/ssrn.3102652 

Schaffner, B. F., Macwilliams, M., & Nteta, T. (2018). Understanding white polarization in the 
2016 vote for president: The sobering role of racism and sexism. Political Science 
Quarterly, 133(1), 9–34. https://doi.org/10.1002/polq.12737 

Villarreal, D. (2020, November 17). Hate crimes under Trump surged nearly 20 percent says FBI 
report. Newsweek. Retrieved December 12, 2021, from 
https://www.newsweek.com/hate-crimes-under-trump-surged-nearly-20-percent-says-fbi-report-1547870. 





